import streamlit as st
import numpy as np
from tensorflow.keras.preprocessing.sequence import pad_sequences
import tensorflow as tf
import pickle

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ø¬ tokenizer
@st.cache_resource
def load_model_and_tokenizer():
    model = tf.keras.models.load_model("model/text_classifier_cnn.h5")  # ØºÙŠÙ‘Ø± Ù‡Ø°Ø§ Ø­Ø³Ø¨ Ø§Ø³Ù… Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    with open("model/tokenizer.pickle", "rb") as f:
        tokenizer = pickle.load(f)
    return model, tokenizer

# ØªØ¹Ø±ÙŠÙ Ø¯Ø§Ù„Ø© Ø§Ù„ØªØµÙ†ÙŠÙ
def classify_text(text, model, tokenizer, id2label, max_length=100):
    sequence = tokenizer.texts_to_sequences([text])
    padded = pad_sequences(sequence, maxlen=max_length, padding='post', truncating='post')
    prediction = model.predict(padded)
    predicted_id = int(np.argmax(prediction))
    predicted_label = id2label.get(str(predicted_id), f"class_{predicted_id}")
    probabilities = {
        id2label.get(str(i), f"class_{i}"): float(prob)
        for i, prob in enumerate(prediction[0])
    }
    return {
        'text': text,
        'predicted_label': predicted_label,
        'predicted_id': predicted_id,
        'probabilities': probabilities
    }

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ø¬
model, tokenizer = load_model_and_tokenizer()

# ØªØ¹Ø±ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª
class_names = [
    "Safe", "Violent Crimes", "Elections", "Sex-Related Crimes", "Unsafe",
    "Non-Violent Crimes", "Child Sexual Exploitation", "Unknown S-Type", "Suicide & Self-Harm"
]
id2label = {str(i): label for i, label in enumerate(class_names)}

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
st.title("Text Classification App")
st.markdown("Ø£Ø¯Ø®Ù„ Ù†ØµÙ‹Ø§ Ù„ÙŠØªÙ… ØªØµÙ†ÙŠÙÙ‡ Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨")

# Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
user_input = st.text_area("ğŸ“ Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ù‡Ù†Ø§", height=150)

# Ø²Ø± Ø§Ù„ØªØµÙ†ÙŠÙ
if st.button("ğŸ” ØªØµÙ†ÙŠÙ"):
    if user_input.strip() == "":
        st.warning("ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù†Øµ Ù„Ù„ØªØµÙ†ÙŠÙ.")
    else:
        result = classify_text(user_input, model, tokenizer, id2label)
        st.subheader("ğŸ” Ø§Ù„Ù†ØªÙŠØ¬Ø©:")
        st.write(f"**Ø§Ù„Ù†Øµ:** {result['text']}")
        st.write(f"**Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:** {result['predicted_label']} (ID: {result['predicted_id']})")

        st.subheader("ğŸ“Š Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ø§Ù„ØªØµÙ†ÙŠÙ:")
        st.bar_chart(result["probabilities"])
