import streamlit as st
import torch
import torch.nn as nn
import re

# ========== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ==========

# Ù†ÙØ³ ØªØµÙ…ÙŠÙ… Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø³Ø§Ø¨Ù‚Ù‹Ø§
class EmbeddingTextClassifier(nn.Module):
    def __init__(self, vocab_size, embed_dim, num_classes):
        super(EmbeddingTextClassifier, self).__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)
        self.fc1 = nn.Linear(embed_dim, 128)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.3)
        self.fc2 = nn.Linear(128, num_classes)

    def forward(self, input_ids):
        x = self.embedding(input_ids)
        x = x.mean(dim=1)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        return x

# ========== Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª ÙˆØ§Ù„ØªÙˆÙƒÙ† ==========

def simple_tokenizer(text):
    text = text.lower()
    text = re.sub(r"[^a-zA-Z0-9\s]", "", text)
    return text.split()

def encode_text(text, vocab, max_len=50):
    tokens = simple_tokenizer(text)
    ids = [vocab.get(token, vocab["<UNK>"]) for token in tokens]
    ids = ids[:max_len] + [vocab["<PAD>"]] * (max_len - len(ids))
    return torch.tensor([ids], dtype=torch.long)

# ========== Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ÙØ¦Ø§Øª ==========

labels_list = [
    "Safe", "Violent Crimes", "Elections", "Sex-Related Crimes", "Unsafe",
    "Non-Violent Crimes", "Child Sexual Exploitation", "Unknown S-Type", "Suicide & Self-Harm"
]

# ========== ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù…ÙØ±Ø¯Ø§Øª ==========

@st.cache_resource
def load_model_and_vocab():
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª (ÙŠÙØªØ±Ø¶ Ø£Ù†Ù‡Ø§ Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ Ù…Ù„Ù .pt Ø£Ùˆ dict)
    vocab = torch.load("model/vocab.pt")  # Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ù… Ù†Ø³Ø®Ø© hardcoded
    
    model = EmbeddingTextClassifier(
        vocab_size=len(vocab),
        embed_dim=100,
        num_classes=len(labels_list)
    )
    model.load_state_dict(torch.load("model/simple_text_classifier.pt", map_location="cpu"))
    model.eval()
    return model, vocab

model, vocab = load_model_and_vocab()

# ========== ÙˆØ§Ø¬Ù‡Ø© Streamlit ==========

st.set_page_config(page_title="ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù†ØµÙŠ", layout="centered")
st.title("ğŸ§  ØªØµÙ†ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ Ø¥Ù„Ù‰ ÙØ¦Ø§Øª Ø§Ù„Ø³Ù„Ø§Ù…Ø©")
st.markdown("Ø§Ø¯Ø®Ù„ Ù†ØµÙ‹Ø§ ÙˆØ³ÙŠÙ‚ÙˆÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙØ¦Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© ğŸ‘‡")

user_input = st.text_area("ğŸ“ Ø£Ø¯Ø®Ù„ Ù†ØµÙ‹Ø§ Ù„Ù„ØªØµÙ†ÙŠÙ", height=150)

if st.button("ğŸ” ØµÙ†Ù Ø§Ù„Ù†Øµ"):
    if not user_input.strip():
        st.warning("Ù…Ù† ÙØ¶Ù„Ùƒ Ø£Ø¯Ø®Ù„ Ù†ØµÙ‹Ø§ Ù‚Ø¨Ù„ Ø§Ù„Ø¶ØºØ· Ø¹Ù„Ù‰ Ø²Ø± Ø§Ù„ØªØµÙ†ÙŠÙ.")
    else:
        input_ids = encode_text(user_input, vocab)
        with torch.no_grad():
            output = model(input_ids)
            predicted_class = torch.argmax(output, dim=1).item()
            st.success(f"ğŸ“Œ Ø§Ù„ÙØ¦Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©: **{labels_list[predicted_class]}**")
