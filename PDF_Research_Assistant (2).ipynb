{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUdu4Q9w5mbv",
        "outputId": "6aebc74c-20e4-499d-809b-15d29b1dc013"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (6.3.0)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.4.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.5)\n",
            "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.6.0)\n",
            "Requirement already satisfied: groq in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==2.0.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<13.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=3.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.21)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.21.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.40.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==2.0.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.0)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.3)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.23.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.39.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.2)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.50.0)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.76.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.0.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (34.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (9.1.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.26.0)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.2.6)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.1)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.43.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: urllib3<2.4.0,>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.6.1)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.13.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.12.19)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.60b1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.3)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=3.0,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=3.0,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=3.0,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio chromadb sentence-transformers langgraph langchain-text-splitters pypdf groq\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber\n"
      ],
      "metadata": {
        "id": "HDCElNxKKKEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n"
      ],
      "metadata": {
        "id": "GcOgQdJlJ8jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U gradio\n"
      ],
      "metadata": {
        "id": "17_goiXd0IOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langgraph.graph import StateGraph\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from pypdf import PdfReader\n",
        "from groq import Groq\n"
      ],
      "metadata": {
        "id": "5jkBIRoE5ty-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key_coder =userdata.get('coder')\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "client = chromadb.Client(Settings(\n",
        "    persist_directory=\"rag_db\",\n",
        "    anonymized_telemetry=False\n",
        "))\n",
        "\n",
        "collection = client.get_or_create_collection(\n",
        "    name=\"pdf_collection\",\n",
        "    metadata={\"hnsw:space\": \"cosine\"}\n",
        ")\n",
        "\n",
        "\n",
        "groq_client = Groq(api_key=api_key_coder)\n"
      ],
      "metadata": {
        "id": "O44OB93u5ytF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pdf_ingest_node(state):\n",
        "    reader = PdfReader(state[\"pdf_path\"])\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        if page.extract_text():\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "\n",
        "    state[\"raw_text\"] = text\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "D_cWQqJU6zFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunking_node(state):\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=800,\n",
        "        chunk_overlap=150\n",
        "    )\n",
        "    state[\"chunks\"] = splitter.split_text(state[\"raw_text\"])\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "-QE-LZH069WS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embedding_node(state):\n",
        "    embeddings = embedding_model.encode(state[\"chunks\"]).tolist()\n",
        "    ids = [f\"chunk_{i}\" for i in range(len(state[\"chunks\"]))]\n",
        "\n",
        "    collection.add(\n",
        "        documents=state[\"chunks\"],\n",
        "        embeddings=embeddings,\n",
        "        ids=ids\n",
        "    )\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "eulnliTZ6yp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieval_node(state):\n",
        "    query_embedding = embedding_model.encode(state[\"question\"]).tolist()\n",
        "\n",
        "    results = collection.query(\n",
        "        query_embeddings=[query_embedding],\n",
        "        n_results=3\n",
        "    )\n",
        "\n",
        "    state[\"context\"] = \"\\n\\n\".join(results[\"documents\"][0])\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "lw9FFtAy6yXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generation_node(state):\n",
        "    prompt = f\"\"\"\n",
        "You are a research assistant.\n",
        "\n",
        "Use the following extracted content from a PDF:\n",
        "{state[\"context\"]}\n",
        "\n",
        "Question:\n",
        "{state[\"question\"]}\n",
        "\n",
        "Answer clearly and accurately.\n",
        "\"\"\"\n",
        "\n",
        "    response = groq_client.chat.completions.create(\n",
        "        model=\"llama3-70b-8192\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.1\n",
        "    )\n",
        "\n",
        "    state[\"answer\"] = response.choices[0].message.content\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "Z815I7gH6yCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = StateGraph(dict)\n",
        "\n",
        "graph.add_node(\"pdf_ingest\", pdf_ingest_node)\n",
        "graph.add_node(\"chunk\", chunking_node)\n",
        "graph.add_node(\"embed\", embedding_node)\n",
        "graph.add_node(\"retrieve\", retrieval_node)\n",
        "graph.add_node(\"generate\", generation_node)\n",
        "\n",
        "graph.set_entry_point(\"pdf_ingest\")\n",
        "\n",
        "graph.add_edge(\"pdf_ingest\", \"chunk\")\n",
        "graph.add_edge(\"chunk\", \"embed\")\n",
        "graph.add_edge(\"embed\", \"retrieve\")\n",
        "graph.add_edge(\"retrieve\", \"generate\")\n",
        "\n",
        "app = graph.compile()\n"
      ],
      "metadata": {
        "id": "FhyGXp3R7RVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(pdf_file) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \"\\n\"\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "TUzqH8sWJnHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_from_pdf(pdf_file, question):\n",
        "    text = extract_text_from_pdf(pdf_file)\n",
        "\n",
        "    # Ø£Ø¶Ù Ù‡Ø°Ø§ Ø§Ù„Ø³Ø·Ø±\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=800,\n",
        "        chunk_overlap=150\n",
        "    )\n",
        "\n",
        "    chunks = splitter.split_text(text)\n",
        "    embeddings = embedding_model.encode(chunks).tolist()\n",
        "\n",
        "    collection.add(\n",
        "        documents=chunks,\n",
        "        embeddings=embeddings,\n",
        "        ids=[str(i) for i in range(len(chunks))]\n",
        "    )\n",
        "\n",
        "    docs = collection.query(\n",
        "        query_embeddings=[embedding_model.encode(question).tolist()],\n",
        "        n_results=3\n",
        "    )\n",
        "\n",
        "    context = \"\\n\".join(docs[\"documents\"][0])\n",
        "\n",
        "    response = groq_client.chat.completions.create(\n",
        "        model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
        "        messages=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Answer based only on the following context:\\n{context}\\n\\nQuestion: {question}\"\n",
        "        }]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "lHDEFYbKByil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "examples = [\n",
        "    [None, \"What is the main idea of this document?\"],\n",
        "    [None, \"Summarize the content briefly.\"],\n",
        "    [None, \"What methodology is used in this paper?\"],\n",
        "    [None, \"What are the key results presented by the author?\"],\n",
        "    [None, \"Explain any important equations or algorithms mentioned.\"],\n",
        "    [None, \"What are the strengths and weaknesses of this work?\"],\n",
        "    [None, \"Does the paper discuss related or previous work?\"],\n",
        "    [None, \"What practical applications are proposed?\"]\n",
        "]\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=answer_from_pdf,\n",
        "    inputs=[\n",
        "        gr.File(\n",
        "            label=\"ğŸ“„ Upload PDF\",\n",
        "            file_types=[\".pdf\"]\n",
        "        ),\n",
        "        gr.Textbox(\n",
        "            label=\"â“ Question\",\n",
        "            lines=2,\n",
        "            placeholder=\"Type your question about the PDF content here...\"\n",
        "        )\n",
        "    ],\n",
        "    outputs=gr.Textbox(\n",
        "        label=\"âœ… Answer\",\n",
        "        lines=8\n",
        "    ),\n",
        "    title=\"ğŸ“š PDF Research Assistant\",\n",
        "    description=\"Upload a PDF file and ask any question related to its content\",\n",
        "    examples=examples\n",
        ")\n",
        "\n",
        "interface.launch(\n",
        "    share=True,\n",
        "    debug=False\n",
        ")"
      ],
      "metadata": {
        "id": "RBVP4Z09x0eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interface = gr.Interface(\n",
        "    fn=answer_from_pdf,\n",
        "    inputs=[\n",
        "        gr.File(label=\"Ø§Ø±ÙØ¹ Ù…Ù„Ù PDF\", file_types=[\".pdf\"]),\n",
        "        gr.Textbox(label=\"Ø§Ù„Ø³Ø¤Ø§Ù„\", lines=2)\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©\"),\n",
        "    title=\"PDF Research Assistant\",\n",
        "    description=\"Ø§Ø±ÙØ¹ Ù…Ù„Ù PDF Ø«Ù… Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„Ù‹Ø§ Ø¹Ù†Ù‡\"\n",
        ")\n",
        "\n",
        "interface.launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "id": "gF5k6PUV7XVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from groq import Groq\n",
        "import pdfplumber\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª\n",
        "api_key_coder = userdata.get('coder')\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "client = chromadb.Client(Settings(\n",
        "    persist_directory=\"rag_db\",\n",
        "    anonymized_telemetry=False\n",
        "))\n",
        "\n",
        "collection = client.get_or_create_collection(\n",
        "    name=\"pdf_collection\",\n",
        "    metadata={\"hnsw:space\": \"cosine\"}\n",
        ")\n",
        "\n",
        "groq_client = Groq(api_key=api_key_coder)\n",
        "\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    \"\"\"Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ù…Ù„Ù PDF\"\"\"\n",
        "    text = \"\"\n",
        "    try:\n",
        "        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù„Ù Ù‡Ùˆ ÙƒØ§Ø¦Ù† Gradio (Ù„Ù‡ Ø®Ø§ØµÙŠØ© name)\n",
        "        file_path = pdf_file.name if hasattr(pdf_file, 'name') else pdf_file\n",
        "\n",
        "        with pdfplumber.open(file_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text + \"\\n\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from PDF: {e}\")\n",
        "        return f\"Error: Could not extract text from PDF. {str(e)}\"\n",
        "\n",
        "    return text\n",
        "\n",
        "def clear_collection():\n",
        "    \"\"\"Ù…Ø³Ø­ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ù‚Ø¨Ù„ Ø¥Ø¶Ø§ÙØ© Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©\"\"\"\n",
        "    try:\n",
        "        client.delete_collection(\"pdf_collection\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    global collection\n",
        "    collection = client.create_collection(\n",
        "        name=\"pdf_collection\",\n",
        "        metadata={\"hnsw:space\": \"cosine\"}\n",
        "    )\n",
        "\n",
        "def answer_from_pdf(pdf_file, question):\n",
        "    \"\"\"Ù…Ø¹Ø§Ù„Ø¬Ø© PDF ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„\"\"\"\n",
        "    if pdf_file is None:\n",
        "        return \"âš ï¸ Please upload a PDF file first.\"\n",
        "\n",
        "    if not question or question.strip() == \"\":\n",
        "        return \"âš ï¸ Please enter a question.\"\n",
        "\n",
        "    try:\n",
        "        # Ù…Ø³Ø­ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©\n",
        "        clear_collection()\n",
        "\n",
        "        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† PDF\n",
        "        text = extract_text_from_pdf(pdf_file)\n",
        "\n",
        "        if text.startswith(\"Error:\"):\n",
        "            return text\n",
        "\n",
        "        if len(text.strip()) == 0:\n",
        "            return \"âš ï¸ Could not extract any text from the PDF. The file might be scanned or encrypted.\"\n",
        "\n",
        "        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡\n",
        "        splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=800,\n",
        "            chunk_overlap=150\n",
        "        )\n",
        "\n",
        "        chunks = splitter.split_text(text)\n",
        "\n",
        "        # Ø¥Ù†Ø´Ø§Ø¡ embeddings\n",
        "        embeddings = embedding_model.encode(chunks).tolist()\n",
        "\n",
        "        # Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
        "        collection.add(\n",
        "            documents=chunks,\n",
        "            embeddings=embeddings,\n",
        "            ids=[f\"chunk_{i}\" for i in range(len(chunks))]\n",
        "        )\n",
        "\n",
        "        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ø£ÙƒØ«Ø± ØµÙ„Ø©\n",
        "        query_embedding = embedding_model.encode(question).tolist()\n",
        "\n",
        "        docs = collection.query(\n",
        "            query_embeddings=[query_embedding],\n",
        "            n_results=3\n",
        "        )\n",
        "\n",
        "        # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø³ÙŠØ§Ù‚\n",
        "        context = \"\\n\".join(docs[\"documents\"][0]) if docs[\"documents\"] else \"No relevant context found.\"\n",
        "\n",
        "        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Groq\n",
        "        prompt = f\"\"\"You are a research assistant. Answer the question based ONLY on the provided context.\n",
        "\n",
        "Context from the document:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Instructions:\n",
        "1. Answer based ONLY on the information in the context above.\n",
        "2. If the context doesn't contain relevant information, say \"The document doesn't contain information about this.\"\n",
        "3. Be clear and concise.\n",
        "4. Provide page references if available.\n",
        "5. Use bullet points for lists when appropriate.\n",
        "\"\"\"\n",
        "\n",
        "        response = groq_client.chat.completions.create(\n",
        "            model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # ÙŠÙ…ÙƒÙ†Ùƒ ØªØºÙŠÙŠØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ø°Ø§ Ø£Ø±Ø¯Øª\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.1,\n",
        "            max_tokens=500\n",
        "        )\n",
        "\n",
        "        answer = response.choices[0].message.content\n",
        "        return answer\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"âŒ An error occurred: {str(e)}\"\n",
        "\n",
        "# Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ§Ø¬Ù‡Ø© Gradio\n",
        "examples = [\n",
        "    [None, \"What is the main idea of this document?\"],\n",
        "    [None, \"Summarize the content briefly.\"],\n",
        "    [None, \"What methodology is used in this paper?\"],\n",
        "    [None, \"What are the key results presented by the author?\"],\n",
        "    [None, \"Explain any important equations or algorithms mentioned.\"],\n",
        "    [None, \"What are the strengths and weaknesses of this work?\"],\n",
        "    [None, \"Does the paper discuss related or previous work?\"],\n",
        "    [None, \"What practical applications are proposed?\"]\n",
        "]\n",
        "\n",
        "# Ø¥ØµØ¯Ø§Ø± Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©\n",
        "interface_en = gr.Interface(\n",
        "    fn=answer_from_pdf,\n",
        "    inputs=[\n",
        "        gr.File(\n",
        "            label=\"ğŸ“„ Upload PDF\",\n",
        "            file_types=[\".pdf\"],\n",
        "            type=\"filepath\"  # Ù‡Ø°Ø§ ÙŠØ¶Ù…Ù† ØªÙ…Ø±ÙŠØ± Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù\n",
        "        ),\n",
        "        gr.Textbox(\n",
        "            label=\"â“ Question\",\n",
        "            lines=2,\n",
        "            placeholder=\"Type your question about the PDF content here...\"\n",
        "        )\n",
        "    ],\n",
        "    outputs=gr.Textbox(\n",
        "        label=\"âœ… Answer\",\n",
        "        lines=10\n",
        "    ),\n",
        "    title=\"ğŸ“š PDF Research Assistant\",\n",
        "    description=\"Upload a PDF file and ask any question related to its content. The system will extract text and provide answers based on the document.\",\n",
        "    examples=examples,\n",
        "    theme=gr.themes.Soft()\n",
        ")\n",
        "\n",
        "# Ø¥ØµØ¯Ø§Ø± Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©\n",
        "interface_ar = gr.Interface(\n",
        "    fn=answer_from_pdf,\n",
        "    inputs=[\n",
        "        gr.File(\n",
        "            label=\"ğŸ“„ Ø§Ø±ÙØ¹ Ù…Ù„Ù PDF\",\n",
        "            file_types=[\".pdf\"],\n",
        "            type=\"filepath\"\n",
        "        ),\n",
        "        gr.Textbox(\n",
        "            label=\"â“ Ø§Ù„Ø³Ø¤Ø§Ù„\",\n",
        "            lines=2,\n",
        "            placeholder=\"Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø­ÙˆÙ„ Ù…Ø­ØªÙˆÙ‰ Ù…Ù„Ù PDF Ù‡Ù†Ø§...\"\n",
        "        )\n",
        "    ],\n",
        "    outputs=gr.Textbox(\n",
        "        label=\"âœ… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©\",\n",
        "        lines=10\n",
        "    ),\n",
        "    title=\"ğŸ“š Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù…Ù„ÙØ§Øª PDF\",\n",
        "    description=\"Ø§Ø±ÙØ¹ Ù…Ù„Ù PDF ÙˆØ§Ø³Ø£Ù„ Ø£ÙŠ Ø³Ø¤Ø§Ù„ Ù…ØªØ¹Ù„Ù‚ Ø¨Ù…Ø­ØªÙˆØ§Ù‡. Ø³ÙŠÙ‚ÙˆÙ… Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ ÙˆØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªÙ†Ø¯.\",\n",
        "    examples=examples,\n",
        "    theme=gr.themes.Soft()\n",
        ")\n",
        "\n",
        "# Ø¥Ù†Ø´Ø§Ø¡ ØªØ¨ÙˆÙŠØ¨Ø§Øª Ù„Ù„ÙˆØ§Ø¬Ù‡ØªÙŠÙ†\n",
        "demo = gr.TabbedInterface(\n",
        "    [interface_en, interface_ar],\n",
        "    [\"English Version\", \"Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©\"]\n",
        ")\n",
        "\n",
        "# ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(\n",
        "        share=True,\n",
        "        debug=False,\n",
        "        server_name=\"0.0.0.0\",\n",
        "        server_port=7860\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "MAo2cd3sGuxZ",
        "outputId": "711bf2e6-c9b7-4e93-99eb-57c4fb4e2c93"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/interface.py:171: UserWarning: The parameters have been moved from the Blocks constructor to the launch() method in Gradio 6.0: theme. Please pass these parameters to launch() instead.\n",
            "  super().__init__(\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/interface.py:171: UserWarning: The parameters have been moved from the Blocks constructor to the launch() method in Gradio 6.0: theme. Please pass these parameters to launch() instead.\n",
            "  super().__init__(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://93bb20f21f05325ea8.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://93bb20f21f05325ea8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}