{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community gradio python-dotenv\n",
        "!pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVklNaAzy2Cy",
        "outputId": "b8996c81-7cea-442c-e2b9-d28d79a0b8a0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.42.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.14)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.11.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.11.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.11.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.11.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: groq in /usr/local/lib/python3.12/dist-packages (0.31.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key_WebSearch =userdata.get('WebSearch')\n",
        "api_key_coder =userdata.get('Chat_with_Your_Context')"
      ],
      "metadata": {
        "id": "_OQt60c-y5Ni"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "from typing import Optional, List, Any, Union, Dict\n",
        "from pydantic import PrivateAttr\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.tools import Tool\n",
        "from langchain.llms.base import LLM\n",
        "from groq import Groq"
      ],
      "metadata": {
        "id": "2sUEWhJMy71X"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Setup LLM using Groq ---\n",
        "class GroqLLM(LLM):\n",
        "    model: str = \"deepseek-r1-distill-llama-70b\"\n",
        "    temperature: float = 0.6\n",
        "    top_p: float = 0.95\n",
        "    max_tokens: int = 4096\n",
        "    api_key: Optional[str] = api_key_coder\n",
        "\n",
        "    _client: Groq = PrivateAttr()\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self._client = Groq(api_key=self.api_key)\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"groq-llm\"\n",
        "\n",
        "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
        "        response = self._client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=self.temperature,\n",
        "            top_p=self.top_p,\n",
        "            max_tokens=self.max_tokens,\n",
        "            stop=stop,\n",
        "            stream=False\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "# --- Activate LLM ---\n",
        "llm = GroqLLM()"
      ],
      "metadata": {
        "id": "mG-gh88FzAQb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Web Search Tool ---\n",
        "class WebSearchError(Exception):\n",
        "    \"\"\"Custom exception for web search failures\"\"\"\n",
        "    pass\n",
        "\n",
        "def web_search(query: str, max_retries: int = 3, timeout: int = 10) -> str:\n",
        "    \"\"\"\n",
        "    Performs a web search using the Tavily API and returns the most relevant result.\n",
        "\n",
        "    Args:\n",
        "        query (str): The search query string\n",
        "        max_retries (int): Maximum number of retry attempts (default: 3)\n",
        "        timeout (int): Request timeout in seconds (default: 10)\n",
        "\n",
        "    Returns:\n",
        "        str: The content of the most relevant search result or an error message\n",
        "\n",
        "    Raises:\n",
        "        WebSearchError: If the search fails after all retry attempts\n",
        "\n",
        "    Example:\n",
        "        >>> result = web_search(\"latest AI research papers 2024\")\n",
        "        >>> print(result)\n",
        "    \"\"\"\n",
        "    api_key = api_key_WebSearch  # Prefer environment variable\n",
        "\n",
        "    if not api_key:\n",
        "        raise WebSearchError(\"API key not configured for web search\")\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": api_key,\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Accept\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    payload = {\n",
        "        \"query\": query,\n",
        "        \"include_raw_content\": True,\n",
        "        \"max_results\": 3  # Get top 3 results for better context\n",
        "    }\n",
        "\n",
        "    last_error = None\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                \"https://api.tavily.com/search\",\n",
        "                headers=headers,\n",
        "                json=payload,\n",
        "                timeout=timeout\n",
        "            )\n",
        "\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "\n",
        "            # Process results with multiple fallback options\n",
        "            if not data.get(\"results\"):\n",
        "                return \"No relevant results found.\"\n",
        "\n",
        "            # Return concatenated content from top 3 results for better context\n",
        "            contents = [r.get(\"content\", \"\") for r in data[\"results\"][:3] if r.get(\"content\")]\n",
        "            return \"\\n\\n\".join(contents) or \"No readable content available.\"\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            last_error = str(e)\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(1 * (attempt + 1))  # Exponential backoff\n",
        "            continue\n",
        "\n",
        "    raise WebSearchError(f\"Web search failed after {max_retries} attempts. Last error: {last_error}\")\n",
        "\n",
        "WebSearchTool = Tool.from_function(\n",
        "    func=web_search,\n",
        "    name=\"WebSearch\",\n",
        "    description=\"\"\"\n",
        "    Powerful web search capability that:\n",
        "    - Retrieves the most up-to-date information from the web\n",
        "    - Returns summarized content from multiple sources\n",
        "    - Handles complex queries with multiple retries\n",
        "    Use when you need current information beyond your knowledge cutoff.\n",
        "    \"\"\",\n",
        "    handle_tool_error=True\n",
        ")"
      ],
      "metadata": {
        "id": "WzQFDlDBzIf1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Context Presence Judge Tool ---\n",
        "def build_context_presence_tool(llm: Any, prompt_path: str) -> Tool:\n",
        "    \"\"\"\n",
        "    Creates a tool that evaluates whether a user query contains sufficient context.\n",
        "\n",
        "    This tool:\n",
        "    - Loads a prompt template from a file\n",
        "    - Formats the template with user input\n",
        "    - Uses an LLM to judge context adequacy\n",
        "    - Returns a ready-to-use Tool object\n",
        "\n",
        "    Args:\n",
        "        llm (Any): The language model instance to use for evaluation\n",
        "        prompt_path (str): Path to the prompt template file\n",
        "\n",
        "    Returns:\n",
        "        Tool: Configured tool for context presence evaluation\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the prompt template file doesn't exist\n",
        "        ValueError: If the prompt template is malformed\n",
        "\n",
        "    Example:\n",
        "        >>> judge_tool = build_context_presence_tool(llm, \"prompts/context_check.txt\")\n",
        "        >>> judge_tool.run(\"What's the capital?||Speaking about France\")\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load prompt template with explicit encoding and error checking\n",
        "        with open(prompt_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            prompt_template = file.read().strip()\n",
        "\n",
        "            if not prompt_template:\n",
        "                raise ValueError(\"Prompt template file is empty\")\n",
        "\n",
        "            if \"{input}\" not in prompt_template:\n",
        "                raise ValueError(\"Prompt template must contain '{input}' placeholder\")\n",
        "\n",
        "        def judge_context_presence(input_text: str) -> str:\n",
        "            \"\"\"\n",
        "            Evaluates whether the input contains sufficient context.\n",
        "\n",
        "            Args:\n",
        "                input_text (str): User input to evaluate\n",
        "\n",
        "            Returns:\n",
        "                str: LLM's judgment about context adequacy\n",
        "            \"\"\"\n",
        "            try:\n",
        "                formatted_prompt = prompt_template.replace(\"{input}\", input_text)\n",
        "                response = llm(formatted_prompt)\n",
        "                return response.strip()\n",
        "            except Exception as e:\n",
        "                return f\"Error evaluating context: {str(e)}\"\n",
        "\n",
        "        return Tool.from_function(\n",
        "            func=judge_context_presence,\n",
        "            name=\"ContextPresenceJudge\",\n",
        "            description=\"\"\"Evaluates whether user queries contain sufficient context.\n",
        "            Use this when you need to determine if additional context is required\n",
        "            to properly answer a question.\"\"\",\n",
        "            handle_tool_error=True\n",
        "        )\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"Prompt template file not found at {prompt_path}\")\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Failed to create context judge tool: {str(e)}\")"
      ],
      "metadata": {
        "id": "HWK-eX6WzL-W"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Enhanced Context Processing Tool ---\n",
        "def Context_Relevance_Splitter(input_text: str) -> Union[str, Dict[str, str]]:\n",
        "    \"\"\"\n",
        "    Advanced context processing with improved error handling and answer extraction.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # If there is no context (no ||)\n",
        "        if \"||\" not in input_text:\n",
        "            return {\n",
        "                \"core_question\": input_text.strip(),\n",
        "                \"background\": \"\",\n",
        "                \"answer_found\": False,\n",
        "                \"query_for_search\": input_text.strip()\n",
        "            }\n",
        "\n",
        "        # Split context from question\n",
        "        parts = [p.strip() for p in input_text.split(\"||\", 1) if p.strip()]\n",
        "\n",
        "        # Check if there are two parts (context and question)\n",
        "        if len(parts) < 2:\n",
        "            return \"âš  Please use the format: question||context\"\n",
        "\n",
        "        context, question = parts[0], parts[1]\n",
        "\n",
        "        # Check context relevance\n",
        "        relevance_prompt = f\"\"\"\n",
        "        Is the following context relevant to the question?\n",
        "        Context: {context}\n",
        "        Question: {question}\n",
        "\n",
        "        Answer only with yes or no:\n",
        "        \"\"\"\n",
        "\n",
        "        relevance_response = llm(relevance_prompt).strip().lower()\n",
        "\n",
        "        if \"yes\" not in relevance_response and \"Ù†Ø¹Ù…\" not in relevance_response:\n",
        "            return {\n",
        "                \"background\": context,\n",
        "                \"core_question\": question,\n",
        "                \"answer_found\": False,\n",
        "                \"query_for_search\": question,\n",
        "                \"message\": \"ðŸš« Irrelevant context - will search for answer externally\"\n",
        "            }\n",
        "\n",
        "        # Try to extract answer from context\n",
        "        answer_extraction_prompt = f\"\"\"\n",
        "        Based on the following context, answer the question.\n",
        "        If the answer is not found in the context, say \"ANSWER_NOT_FOUND\".\n",
        "\n",
        "        Context: {context}\n",
        "        Question: {question}\n",
        "\n",
        "        Answer:\n",
        "        \"\"\"\n",
        "\n",
        "        answer_response = llm(answer_extraction_prompt).strip()\n",
        "\n",
        "        # Check if answer was found in context\n",
        "        if \"ANSWER_NOT_FOUND\" in answer_response.upper():\n",
        "            return {\n",
        "                \"background\": context,\n",
        "                \"core_question\": question,\n",
        "                \"answer_found\": False,\n",
        "                \"query_for_search\": question,\n",
        "                \"extracted_answer\": None,\n",
        "                \"message\": \"Answer not found in context - requires external search\"\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                \"background\": context,\n",
        "                \"core_question\": question,\n",
        "                \"answer_found\": True,\n",
        "                \"query_for_search\": None,\n",
        "                \"extracted_answer\": answer_response,\n",
        "                \"message\": \"Answer successfully extracted from context\"\n",
        "            }\n",
        "\n",
        "    except Exception as e:\n",
        "        # In case of any unexpected error\n",
        "        return {\n",
        "            \"core_question\": input_text.strip(),\n",
        "            \"background\": \"\",\n",
        "            \"answer_found\": False,\n",
        "            \"query_for_search\": input_text.strip(),\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "# --- Agent Tool Definition ---\n",
        "Context_Relevance_Splitter_tool = Tool.from_function(\n",
        "    func=Context_Relevance_Splitter,\n",
        "    name=\"ContextProcessor\",\n",
        "    description=\"\"\"\n",
        "    Advanced context processing and answer extraction tool:\n",
        "    1. Checks relevance of context to the question\n",
        "    2. Attempts to extract answer from context\n",
        "    3. If answer not found, returns query for external search\n",
        "    4. Splits context from the core question\n",
        "    Use format: question||context\n",
        "    Returns: answer_found, extracted_answer, query_for_search\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "ryUwxicY5dVx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure this prompt file exists with appropriate content\n",
        "context_tool = build_context_presence_tool(llm, prompt_path=\"context_judge_prompt.txt\")\n",
        "\n",
        "# --- Agent initialization with all tools ---\n",
        "tools = [context_tool,\n",
        "    Context_Relevance_Splitter_tool,\n",
        "    WebSearchTool\n",
        "]\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    handle_parsing_errors=True,\n",
        "    verbose=True,\n",
        "    max_iterations=5\n",
        ")\n",
        "\n",
        "# --- Enhanced Agent Runner Function ---\n",
        "def run_agent(user_input):\n",
        "    try:\n",
        "        # Initial context processing\n",
        "        context_result = Context_Relevance_Splitter_tool(user_input)\n",
        "\n",
        "        # If result is a string (error message)\n",
        "        if isinstance(context_result, str):\n",
        "            if \"ðŸš«\" in context_result or \"âš \" in context_result:\n",
        "                return context_result\n",
        "            else:\n",
        "                final_question = user_input\n",
        "                background = \"\"\n",
        "        else:\n",
        "            # If result is a dictionary (successful processing)\n",
        "            final_question = context_result.get('core_question', user_input)\n",
        "            background = context_result.get('background', '')\n",
        "\n",
        "        # Build final agent input\n",
        "        if background:\n",
        "            enhanced_input = f\"\"\"\n",
        "            Context Background: {background}\n",
        "            Question: {final_question}\n",
        "            \"\"\"\n",
        "        else:\n",
        "            enhanced_input = final_question\n",
        "\n",
        "        # Run agent with final input\n",
        "        return agent.run(enhanced_input)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"â›” Unexpected error occurred: {str(e)}\\nPlease rephrase your question or try again later.\"\n",
        "\n",
        "# --- Enhanced Gradio Interface ---\n",
        "interface = gr.Interface(\n",
        "    fn=run_agent,\n",
        "    inputs=gr.Textbox(\n",
        "        lines=3,\n",
        "        placeholder=\"Enter your question here...\\nTo add context use format: Question||Context\\nExample: What's France's capital||Speaking about a European country\"\n",
        "    ),\n",
        "    outputs=\"text\",\n",
        "    title=\"ðŸ¤– Context-Aware Smart Agent\",\n",
        "    description=\"\"\"\n",
        "    Advanced system for understanding complex questions:\n",
        "    - Supports external context using ||\n",
        "    - Automatically get the answer from context\n",
        "    - Answers directly or searches when needed\n",
        "    \"\"\",\n",
        "    examples=[\n",
        "        [\"Ø§Ù„Ø¹Ø§ØµÙ…Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Ù‡ÙŠ Ø§Ù„Ø±ÙŠØ§Ø¶||Ù…Ø§ Ù‡ÙŠ Ø¹Ø§ØµÙ…Ø© Ù…ØµØ±ØŸ\"],\n",
        "        [\"Ø§Ù„Ø¹Ø§ØµÙ…Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Ù‡ÙŠ Ø§Ù„Ø±ÙŠØ§Ø¶||Ù…Ø§ Ù‡ÙŠ Ø¹Ø§ØµÙ…Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©ØŸ\"]\n",
        "    ]\n",
        ")\n",
        "\n",
        "# --- Launch Interface ---\n",
        "if __name__ == \"__main__\":\n",
        "    interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "KZV158VDzaY6",
        "outputId": "919bf948-82dc-4e96-eb06-c71bcaa3c2c5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://63fca5194ca9128f67.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://63fca5194ca9128f67.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rl4wQ_OGJb7h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
